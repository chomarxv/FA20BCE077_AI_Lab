{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qzSNZmKnAN8",
        "outputId": "5af810b6-0249-4992-b966-43c7b6222f81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "938/938 [==============================] - 49s 52ms/step - loss: 0.1702 - accuracy: 0.9485 - val_loss: 0.0595 - val_accuracy: 0.9808\n",
            "Epoch 2/5\n",
            "938/938 [==============================] - 50s 53ms/step - loss: 0.0536 - accuracy: 0.9834 - val_loss: 0.0316 - val_accuracy: 0.9894\n",
            "Epoch 3/5\n",
            "938/938 [==============================] - 47s 50ms/step - loss: 0.0374 - accuracy: 0.9884 - val_loss: 0.0340 - val_accuracy: 0.9888\n",
            "Epoch 4/5\n",
            "938/938 [==============================] - 49s 53ms/step - loss: 0.0277 - accuracy: 0.9911 - val_loss: 0.0374 - val_accuracy: 0.9884\n",
            "Epoch 5/5\n",
            "938/938 [==============================] - 48s 52ms/step - loss: 0.0216 - accuracy: 0.9932 - val_loss: 0.0303 - val_accuracy: 0.9896\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0303 - accuracy: 0.9896\n",
            "Test Accuracy: 0.9896000027656555\n"
          ]
        }
      ],
      "source": [
        "#Import necessary libraries\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Load and preprocess the MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "# Reshape and normalize the images\n",
        "train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255\n",
        "test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255\n",
        "\n",
        "# One-hot encode the labels\n",
        "train_labels = to_categorical (train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "# Build the CNN model\n",
        "model = Sequential()\n",
        "# Step 1: Convolutional Layer with ReLU activation\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "# Step 2: Max Pooling Layer\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "# Step 3: Convolutional Layer with ReLU activation\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "# Step 4: Max Pooling Layer\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "# Step 5: Flatten Layer\n",
        "model.add(Flatten())\n",
        "# Step 6: Dense (Fully Connected) Layer with ReLU activation\n",
        "model.add(Dense (64, activation='relu'))\n",
        "# Step 7: Output Layer with Softmax activation (for multi-class classification)\n",
        "model.add(Dense (10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#Train the model\n",
        "model.fit(train_images, train_labels, epochs=5, batch_size=64, validation_data=(test_images,\n",
        "test_labels))\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print (f'Test Accuracy: {test_acc}')"
      ]
    }
  ]
}